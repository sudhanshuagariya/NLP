import nltk
nltk.download("popular")
[nltk_data] Downloading collection 'popular'
[nltk_data]    | 
[nltk_data]    | Downloading package cmudict to /root/nltk_data...
[nltk_data]    |   Unzipping corpora/cmudict.zip.
[nltk_data]    | Downloading package gazetteers to /root/nltk_data...
[nltk_data]    |   Unzipping corpora/gazetteers.zip.
[nltk_data]    | Downloading package genesis to /root/nltk_data...
[nltk_data]    |   Unzipping corpora/genesis.zip.
[nltk_data]    | Downloading package gutenberg to /root/nltk_data...
[nltk_data]    |   Unzipping corpora/gutenberg.zip.
[nltk_data]    | Downloading package inaugural to /root/nltk_data...
[nltk_data]    |   Unzipping corpora/inaugural.zip.
[nltk_data]    | Downloading package movie_reviews to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Unzipping corpora/movie_reviews.zip.
[nltk_data]    | Downloading package names to /root/nltk_data...
[nltk_data]    |   Unzipping corpora/names.zip.
[nltk_data]    | Downloading package shakespeare to /root/nltk_data...
[nltk_data]    |   Unzipping corpora/shakespeare.zip.
[nltk_data]    | Downloading package stopwords to /root/nltk_data...
[nltk_data]    |   Unzipping corpora/stopwords.zip.
[nltk_data]    | Downloading package treebank to /root/nltk_data...
[nltk_data]    |   Unzipping corpora/treebank.zip.
[nltk_data]    | Downloading package twitter_samples to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Unzipping corpora/twitter_samples.zip.
[nltk_data]    | Downloading package omw to /root/nltk_data...
[nltk_data]    |   Unzipping corpora/omw.zip.
[nltk_data]    | Downloading package wordnet to /root/nltk_data...
[nltk_data]    |   Unzipping corpora/wordnet.zip.
[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...
[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.
[nltk_data]    | Downloading package words to /root/nltk_data...
[nltk_data]    |   Unzipping corpora/words.zip.
[nltk_data]    | Downloading package maxent_ne_chunker to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.
[nltk_data]    | Downloading package punkt to /root/nltk_data...
[nltk_data]    |   Unzipping tokenizers/punkt.zip.
[nltk_data]    | Downloading package snowball_data to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    | Downloading package averaged_perceptron_tagger to
[nltk_data]    |     /root/nltk_data...
[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.
[nltk_data]    | 
[nltk_data]  Done downloading collection popular
Out[1]:
True
In [2]:
#word tokenize
from nltk.tokenize import word_tokenize as wt
text = "Sitting on a branch, the monkey gibbered."
print(wt(text))
['Sitting', 'on', 'a', 'branch', ',', 'the', 'monkey', 'gibbered', '.']
In [3]:
#sentence tokenization
from nltk.tokenize import sent_tokenize
text = "Not only in the corporate sector, but women have also been in the limelight for their immaculate performances in the field of sports, drama, and music."
print(sent_tokenize(text))
['Not only in the corporate sector, but women have also been in the limelight for their immaculate performances in the field of sports, drama, and music.']
In [4]:
#stop words
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
nltk.download('stopwords')
nltk.download('punkt')
[nltk_data] Downloading package stopwords to /root/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package punkt to /root/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
Out[4]:
True
In [6]:
print(stopwords.words('english'))

text = "This is a really nice plan."
text_tokens = word_tokenize(text)

tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]

print(text_tokens)
print(tokens_without_sw)
['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', "you're", "you've", "you'll", "you'd", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', "she's", 'her', 'hers', 'herself', 'it', "it's", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', "that'll", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', "don't", 'should', "should've", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', "aren't", 'couldn', "couldn't", 'didn', "didn't", 'doesn', "doesn't", 'hadn', "hadn't", 'hasn', "hasn't", 'haven', "haven't", 'isn', "isn't", 'ma', 'mightn', "mightn't", 'mustn', "mustn't", 'needn', "needn't", 'shan', "shan't", 'shouldn', "shouldn't", 'wasn', "wasn't", 'weren', "weren't", 'won', "won't", 'wouldn', "wouldn't"]
['This', 'is', 'a', 'really', 'nice', 'plan', '.']
['This', 'really', 'nice', 'plan', '.']
In [7]:
#stemming
from nltk.stem.porter import *

porterStemmer = PorterStemmer()

sentence="Women are hard and successful workers because without them, the family will stop functioning. Out of conditioning since childhood, women have learnt to handle responsibilities, and now they are working their way up the rungs of the corporate ladder as well."
wordList = nltk.word_tokenize(sentence)

stemWords = [porterStemmer.stem(word) for word in wordList]

print(' '.join(stemWords))
women are hard and success worker becaus without them , the famili will stop function . out of condit sinc childhood , women have learnt to handl respons , and now they are work their way up the rung of the corpor ladder as well .
In [8]:
#word lemma
from nltk.stem import WordNetLemmatizer
wordnet_lemmatizer = WordNetLemmatizer()

sentence = "The Indian economy is diverse and embraces a huge area including agriculture, mining, textile industry, manufacturer and a vast area of other services. There is an enormous shift from what the economy used to be in the distant past. Indian economy is the third largest in the world, as measured by ‘Purchasing Power Parity’ (PPP)."
punctuations="?:!.,;"
sentence_words = nltk.word_tokenize(sentence)
for word in sentence_words:
    if word in punctuations:
        sentence_words.remove(word)

sentence_words
print("{0:20}{1:20}".format("Word","Lemma"))
for word in sentence_words:
    print ("{0:20}{1:20}".format(word,wordnet_lemmatizer.lemmatize(word)))
Word                Lemma               
The                 The                 
Indian              Indian              
economy             economy             
is                  is                  
diverse             diverse             
and                 and                 
embraces            embrace             
a                   a                   
huge                huge                
area                area                
including           including           
agriculture         agriculture         
mining              mining              
textile             textile             
industry            industry            
manufacturer        manufacturer        
and                 and                 
a                   a                   
vast                vast                
area                area                
of                  of                  
other               other               
services            service             
There               There               
is                  is                  
an                  an                  
enormous            enormous            
shift               shift               
from                from                
what                what                
the                 the                 
economy             economy             
used                used                
to                  to                  
be                  be                  
in                  in                  
the                 the                 
distant             distant             
past                past                
Indian              Indian              
economy             economy             
is                  is                  
the                 the                 
third               third               
largest             largest             
in                  in                  
the                 the                 
world               world               
as                  a                   
measured            measured            
by                  by                  
‘                   ‘                   
Purchasing          Purchasing          
Power               Power               
Parity              Parity              
’                   ’                   
(                   (                   
PPP                 PPP                 
)                   )                   
In [9]:
from nltk import word_tokenize, pos_tag
from nltk.stem import WordNetLemmatizer
wnl = WordNetLemmatizer()
txt = """India is mainly an agricultural economy. Agricultural activities contribute about 50% of the economy. Agriculture involves growing and selling of crops, poultry, fishing, cattle rearing, and animal husbandry. People in India earn their livelihood by involving themselves in many of these activities."""
[wnl.lemmatize(i,j[0].lower()) if j[0].lower() in ['a','n','v'] else wnl.lemmatize(i) for i,j in pos_tag(word_tokenize(txt))]
Out[9]:
['India',
 'be',
 'mainly',
 'an',
 'agricultural',
 'economy',
 '.',
 'Agricultural',
 'activity',
 'contribute',
 'about',
 '50',
 '%',
 'of',
 'the',
 'economy',
 '.',
 'Agriculture',
 'involve',
 'grow',
 'and',
 'selling',
 'of',
 'crop',
 ',',
 'poultry',
 ',',
 'fishing',
 ',',
 'cattle',
 'rearing',
 ',',
 'and',
 'animal',
 'husbandry',
 '.',
 'People',
 'in',
 'India',
 'earn',
 'their',
 'livelihood',
 'by',
 'involve',
 'themselves',
 'in',
 'many',
 'of',
 'these',
 'activity',
 '.']
In [ ]:
